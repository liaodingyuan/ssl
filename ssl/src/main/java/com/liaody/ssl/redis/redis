1.使用type命令：none (key不存在)、string (字符串)、list (列表)、set (集合)、zset (有序集)、hash (哈希表)、stream （流）
2.scan命令
从直觉上可以看出， 当一个数据集不断地变大时， 想要访问这个数据集中的所有元素就需要做越来越多的工作，
能否结束一个迭代取决于用户执行迭代的速度是否比数据集增长的速度更快。
p
可能会造成数据重复，这个需要客户端来进行保证。

3.生存时间
如果一个命令只是修改(alter)一个带生存时间的 key 的值而不是用一个新的 key 值来代替(replace)它的话，那么生存时间不会被改变。
另一方面，如果使用 RENAME 对一个 key 进行改名，那么改名后的 key 的生存时间和改名前一样。

RENAME 命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，
这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。
使用 PERSIST 命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个『持久的』(persistent) key 。

4.事务
MULTI
    Redis Command
EXEC
DISCARD
WATCH:监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。
在事务种需要操作这一个key

UNWATCH:取消 WATCH 命令对所有 key 的监视。
        如果在执行 WATCH 命令之后， EXEC 命令或 DISCARD 命令先被执行了的话，那么就不需要再执行 UNWATCH 了。
        因为 EXEC 命令会执行事务，因此 WATCH 命令的效果已经产生了；
        而 DISCARD 命令在取消事务的同时也会取消所有对 key 的监视，因此这两个命令执行之后，就没有必要执行 UNWATCH 了。

和传统的mysql事务不同的事，即使我们的加钱操作失败,我们也无法在这一组命令中让整个状态回滚到操作之前（特别是产生运行时
错误的时候，错误的redis命令不会被执行，但是正确的redis命令已经被执行无法撤销，客户端要保证这是没有问题的）。

事务执行错误：
语法错误：运行前redis已经检测出，这时候exec，即使在队列中正确的redis命令也不会执行
运行错误：运行时才能够检测出，这时候exec，错误的给出错误警告，正确的会被执行。Redis的事务没有关系数据库事务提供的回滚（rollback）功能。为此开发者必须在事务执行出错后自己收拾剩下的摊子（将数据库复原回事务执行前的状态等,
这里我们一般采取日志记录然后业务补偿的方式来处理，但是一般情况下，在redis做的操作不应该有这种强一致性要求的需求，我们认为这种需求为不合理的设计）。


5.高级数据结构
HyperLogLog：
基数:一个几何中不同值得数目，基数也可以称之为Distinct Value，简称DV。HyperLogLog就是用来计算基数的。
比如[a,b,c,d]的基数就是4，[a,b,c,d,a]的基数还是4，因为a重复了一个，不算。
调和平均数：求平均数的时候会被大数值的影响，使用平均调和数解决这一个问题。调和平均数的结果会倾向于集合中比较小的数。

HyperLogLog是一种基数算法，通过HyperLogLog可以利用绩效的内存空间完成独立总数的统计。

影响LogLog算法精度的一个重要因素就是，hash值的前导零的数量显然是有很大的偶然性的，经常会出现一两数据前导零的数目比较多的情况，
所以HyperLogLog算法相比LogLog算法一个重要的改进就是使用调和平均数而不是平均数来聚合每个桶中的结果，HyperLogLog算法的公式如下：

redis种的三个数据
PFADD：将元素添加到hyperloglog中
PFCOUNT：计算hyperloglog中的基数
PFMERGE：合并两个hyperloglog
每个 HyperLogLog 只需使用 12k 字节内存，以及几个字节的内存来储存键本身）。
命令返回的可见集合（observed set）基数并不是精确值， 而是一个带有 0.81% 标准错误（standard error）的近似值。

使用HyperLogLog作为用户统计用户访问量、但是因为可能存在误差，最后被pass掉了，
使用Bitmaps，字符串形式的位图


如： Bitmaps和HyperLogLog使用字符串实
现， GEO使用有序集合实现等。

7.redis的key
空字符串也是有效的key值。key不建议太长，这样查找效率比较低。也不能太短，不然看不出来是什么意思。
最好坚持使用同一种key模式，比如 "user:1000:password"

redis key是二进制安全的，可以使用任意二进制序列作为key值。值的长度不能够大于512M。

incr和decr还有其他类似的命令，都是都是原子操作的，不会有竞争条件的发生。是安全的。

使用getset
你的系统每当有新用户访问时就用INCR命令操作一个Redis key。你希望每小时对这个信息收集一次。
你就可以GETSET这个key并给其赋值0并读取原值。

key和value的最大值都是512MB
set key value [ex seconds] [px millisecondes] [nx|xx]
setrange key offset value
getrange kfey start end

setnx可以作为Redis分布式锁的实现

*key的内部编码
int ： 8个字节的长整形
embstr ：小于等于39字节的字符串
raw：大于39字节的字符串

比较推荐的方式是使用“业务名： 对象名： id： [属性]”作为键名（也可以不是分号）

使用redis作为缓存、技术、共享session、鉴权信息、使用redis进行限速

8.redis的list（有序）
Redis lists基于Linked Lists实现。这意味着即使在一个list中有数百万个元素，在头部或尾部添加一个元素的操作，其时间复杂度也是常数级别的
在数组实现的list中利用索引访问元素的速度极快，而同样的操作在linked list实现的list上没有那么快。
如果快速访问集合元素很重要，建议使用可排序集合(sorted sets)。

List上的阻塞操作
可以使用Redis来实现生产者和消费者模型，如使用LPUSH和RPOP来实现该功能。但会遇到这种情景：list是空，
这时候消费者就需要轮询来获取数据，这样就会增加redis的访问压力、增加消费端的cpu时间，而很多访问都是无用的。
为此redis提供了阻塞式访问 BRPOP 和 BLPOP 命令。 消费者可以在获取数据时指定如果数据不存在阻塞的时间，
如果在时限内获得数据则立即返回，如果超时还没有数据则返回null, 0表示一直阻塞。
同时redis还会为所有阻塞的消费者以先后顺序排队

最近有一个项目是点击日志（10亿/天）实时计算，架构上简单来说就是利用flunted去从前端机收集原始日志，然后发给Kafka，Spark消费日志并计算保存结果到Redis。
Kafka的Producer和Consumer端的配置是异步且保证不丢消息，因此当超时发生时，就可能会导致消息的重发或者重复消费，需要在消费环节保证幂等。
Spark消费逻辑主要是根据多个维度进行计数计算，因此，我们需要在计算之前去重来保证不重复计数。

lrrange key start end

阻塞操作：blpop brpop key timeout(秒)  如果使用非阻塞命令然后一直轮询redis会造成
redis服务器的阻塞
在使用brpop时， 有两点需要注意：
第一点， 如果是多个键， 那么brpop会从左至右遍历键， 一旦有一个键113能弹出元素， 客户端立即返回。
第二点：如果多个客户端对同一个键执行brpop， 那么最先执行brpop命令的客户端可以获取到弹出的值。

内置编码：
ziplist(hash也会使用这一种编码)
linkelist
元素个数小于hash-max-ziplist-entires配置且所有的值都小于hash-max-ziplist-value配置，
使用ziplist编码；否则使用hashtable编码
Redis3.2版本提供了quicklist内部编码， 简单地说它是以一个ziplist为节点的linkedlist， 它结合了ziplist和linkedlist两者的优势

使用场景：Redis的lpush+brpop命令组合即可实现阻塞队列， 生产
     者客户端使用lrpush从列表左侧插入元素， 多个消费者客户端使用brpop命令
     阻塞式的“抢”列表尾部的元素， 多个客户端保证了消费的负载均衡和高可用
     性。

文章列表：每个用户有属于自己的文章列表， 现需要分页展示文章列表。 此时可以
     考虑使用列表， 因为列表不但是有序的， 同时支持按照索引范围获取元素。

9.理解Redis的单线程模型与IO多路复用复用模型
因为Redis是单线程的，所以所有的命令到达redis server的时候服务器不会立即执行。而是所有的命令都进入一个队列

10.单线程的Redis为什么那么快。
第一是纯内存访问
第二是非阻塞IO：Redis使用epoll作为多路I/O多路复用技术的实现
第三单线程避免了线程切换和竞争状态产生的消耗

单要注意的是：单线程的Redis命令如果执行太耗时间，会阻塞其他命令的执行

11.哈希 hash
hset key field value (批量 hmget hmset)
hget key field

hdel key field
#求个数
hlen
hkeys key 、hvals key。
注意不要使用hgetall，当field过多的时候会阻塞redis，造成和keys命令一样的后果，
可以使用hscan命令。

hash的内部编码：
ziplist：
hashtable
元素个数小于hash-max-ziplist-entires配置且所有的值都小于hash-max-ziplist-value配置，
使用ziplist编码；否则使用hashtable编码

使用场景：

12.list的作用
lpush+lpop=Stack（栈）
lpush+rpop=Queue（队列）
lpush+brpop=Messgae Queue（消息队列）

13.Set集合
Redis除了支持集合内的增删改查， 同时还支持多个集合取交集、 并集、 差集， 合理地使用好集合类型， 能在实际开发中解决很多实际问题
sismember key element
scard 求set的长度

内部编码：
intset（整数集合） ： 当集合中的元素都是整数且元素个数小于set-maxintset-entries配置（默认512个） 时， Redis会选用intset来作为集合的内部实
现， 从而减少内存的使用。
·hashtable（哈希表） ： 当集合类型无法满足intset的条件时， Redis会使
用hashtable作为集合的内部实现

多个数据集合交集：sinter set1 set2 ...
求多个集合的并集：sunion set1 set2
求多个集合差集：sdiff set1 set2

sinterstore destination key [key ...]
suionstore destination key [key ...]
sdiffstore destination key [key ...]

使用set的场景：tag标签，
给用户添加标签：sadd user:1:tags tag1 tag2 tag5
给标签添加用户：sadd tag2:users user:1 user:2 user:3

14.有序集合sort set
有序集合中的元素不能重复， 但是score可以重复。

15.Pipeline
发送命令->命令排队->命令执行->返回结果

16。BitMap
BitMap科尔一说并不是一种数据结构，实际上它就是字符串，但是它可以对字符串
的位进行操作。
可以把Bitmaps想象成一个以位为单位的数组， 数组的
每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。

setbit key offset value
使用Bitmap判断用户是否已经访问过:
将访问的用户记作1，没有访问过的用户记作0，用用户的偏移量作为用户的id
setbit unique:users:2016-04-05 19 1
获取Bitmaps中指定范围1的个数：bitcount [start] [end]

17.Redis的发布订阅机制
一个channel可以被多个订阅者订阅,一个订阅者也可以订阅多个chanel
有关订阅命令有两点需要注意：
·客户端在执行订阅命令之后进入了订阅状态， 只能接收subscribe、
psubscribe、 unsubscribe、 punsubscribe的四个命令。
·新开启的订阅客户端， 无法收到该频道之前的消息， 因为Redis不会对
发布的消息进行持久化

18.绕不开的Redis持久化
RDB快照方式或者AOF文件追加方式

RDB：
触发RDB持久化的方式分为手动和被动的方式。
手动触发:save和bgsave命令：
save：save命令： 阻塞当前Redis服务器， 直到RDB过程完成为止， 对于内存
     比较大的实例会造成长时间阻塞， 线上环境不建议使用。（应该说是已经废除这一种方式，禁止使用）
bgsave：Redis进程执行fork操作创建子进程， RDB持久化过程由子
       进程负责， 完成后自动结束。 阻塞只发生在fork阶段， 一般时间很短

文件名通过dbfilename指定、文件目录通过dir指定
自动触发：
1.在redis.conf中配置了save m n的配置，表示m秒内数据集存在n次修改时， 自动触发bgsave
2.从节点执全量复制，主节点自动执行bgsave生成RDB文件并发送给从节点。
3.执行debug reload命令重新加载Redis时， 也会自动触发save操作。
4.默认情况下执行shutdown命令时， 如果没有开启AOF持久化功能则自动执行bgsave

建议开启RDB压缩

读取到的RDB文件已经损坏
# Short read or OOM loading DB. Unrecoverable error, aborting now.
使用redis-check-dump进行修复

优点是速度快
命令写入（append） 、 文件同步（sync） 、 文件重写（rewrite） 、 重启加载（load）

19.Redis的复制
slaveof host port 执行复制过程
当主节点配置了密码之后，客户都安连接需要auth。
从节点复制的时候要在conf文件中配置masterauth，才能发起正确的复制流程。

读写分离出现的问题：，数据复制延迟、在从节点上读取到了过期的数据、从节点发生了功夫扎实那个
数据复制延迟：网络延迟和阻塞是不可避免的，可以编写监控程序读取主节点偏移量和从节点偏移量，相差过大的发出警告。
读到过期的数据：
从节点故障：Redis的主从复制模式下， 一旦主节点由于故障不能提供服务， 需要人
      工将从节点晋升为主节点， 同时还要通知应用方更新主节点地址， 对于很多
      应用场景这种故障处理的方式是无法接受的。 （使用哨兵模式）

20.阻塞
API或数据结构使用不合理、CPU饱和的问题、持久化相关的阻塞

*Api或数据结构使用不合理:执行slowlog get{n}命令可以获取最近
              的n条慢查询命令， 默认对于执行超过10毫秒的命令都会记录到一个定长队
              列中， 线上实例建议设置为1毫秒便于及时发现毫秒级以上的命令。 如果命
              令执行时间在毫秒级， 则实例实际OPS只有1000左右。
但是要注意的是，慢查询只是记录了Redis命令执行的慢时间，不包括网络延迟。

使用 redis-cli -h ip -p port --bigkeys 发现大对象

*CPU饱和
单线程的Redis处理命令时只能使用一个CPU。 而CPU饱和是指Redis把
单核CPU使用率跑到接近100%。 使用top命令很容易识别出对应Redis进程的
CPU使用率。 CPU饱和是非常危险的， 将导致Redis无法处理更多的命令， 严
重影响吞吐量和应用方的稳定性。 对于这种情况， 首先判断当前Redis的并
发量是否达到极限， 建议使用统计命令redis-cli-h{ip}-p{port}--stat获取当前
Redis使用情况， 该命令每秒输出一行统计信息。

*持久化的阻塞
fork阻塞、 AOF刷盘阻塞、HugePage写操作阻塞。

21.哨兵
主从模式，主节点挂了之后，从节点不能够直接升为主节点，需要人工去升级主节点，并将下线的从节点告知哭护短
Redis Sentinel是Redis的高可用实现方案， 在实际的生产环境中， 对提高整个系统的高可用性是非常有帮助的
slaveof no one会使从节点升为主节点，代原来的主节点恢复之后，让它去复制新的主节点数据，变为从节点

一主二从三哨兵
配置主从
主节点：
redis-6379.conf
port 6379
daemonize yes
logfile "6379.log"
dbfilename "dump-6379.rdb"
dir "/opt/soft/redis/data/"
判断redis是否启动成功：redis-cli -h 127.0.0.1 -p 6379 ping

从节点与主节点不一样的地方就是多了一个slaveof配置项
redis-6380.conf
port 6380
daemonize yes
logfile "6380.log"
dbfilename "dump-6380.rdb"
dir "/opt/soft/redis/data/"
slaveof 127.0.0.1 6379

分别启动主节点和从节点

配置哨兵
redis-sentinel-26379.conf
port 26379
daemonize yes
logfile "26379.log"
dir /opt/soft/redis/data
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 30000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 180000

使用命令启动哨兵：redis-sentinel redis-sentinel-26379.conf
确认哨兵是否已经启动成功：
$ redis-cli -h 127.0.0.1 -p 26379 info Sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
master0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=2,sentinels=3

注意：
1） 生产环境中建议Redis Sentinel的所有节点应该分布在不同的物理机上。
2） Redis Sentinel中的数据节点和普通的Redis数据节点在配置上没有任
何区别， 只不过是添加了一些Sentinel节点对它们进行监控。

部署技巧
*哨节点不应该部署在一台物理机上
*部署至少三个基数的sentinel
*如果Sentinel节点集合监控的是同一个业务的多个主节点集合， 那么使 用方案：一台Sentinel监控多个主节点、 否则使用多套setinel监控多个多套个主节点


22.集群方案
数据的分布理论：分区规则有哈希分区和顺序分区。
Redis cluster采用的是hash分区：离散度好、数据分布业务无关、但是无法顺序访问
顺序分区：离散度倾斜、、数分布相关、可以顺序访问。

节点取余分区、一致性hash分区（灵魂拷问：理解一致性hash）
一致性hash分区：是为系统中每个节
          点分配一个token， 范围一般在0~232， 这些token构成一个哈希环。 数据读写
          执行节点查找操作时， 先根据key计算hash值， 然后顺时针找到第一个大于
          等于该哈希值的token节点， 如图10-3所示
虚拟槽分区：使用分散度良好的哈希函数把所有
      数据映射到一个固定范围的整数集合中， 整数定义为槽（slot） 。 这个范围
      一般远远大于节点数， 比如Redis Cluster槽范围是0~16383。 槽是集群内数据
      管理和迁移的基本单位。 采用大范围槽的主要目的是为了方便数据拆分和集
      群扩展
Redis Cluster采用虚拟槽分区，所有的键根据哈希函数映射到0-16383.每一个节点负责维护一部分槽以及槽锁映射的键值数据。

集群功能限制（重点）：
key事务操作支持有限。 同理只支持多key在同一节点上的事务操作， 当多个key分布在不同的节点上时无法使用事务功能
key作为数据分区的最小粒度， 因此不能将一个大的键值对象如hash、 list等映射到不同的节点。（不支持数据分片）
不支持多数据库空间。 单机下的Redis可以支持16个数据库， 集群模式下只能使用一个数据库空间， 即db0。
复制结构只支持一层， 从节点只能复制主节点， 不支持嵌套树状复制结构
you can't have keys in a different than db0 when in cluster mode。


只要16384个槽中有
一个没有分配给节点则表示集群不完整。 可以使用redis-cli.rb check ip:port命令检测之前创建的两个集群是否成功

redis cluster 采用Gossip协议工作原理就是节点彼此不断通信交换信息， 一段时间后所有的节
                点都会知道集群完整的信息， 这种方式类似流言传播。

Gossip消息：常用的Gossip消息可分为： ping消息、 pong消息、 meet消息、 fail消息
meet：用于通知新节点加入。消息发送者通知接收者加入到当前
               集群， meet消息通信正常完成后， 接收节点会加入到集群中并进行周期性的
               ping、 pong消息交换

fail消息： 当节点判定集群内另一个节点下线时， 会向集群内广播一个fail消息， 其他节点接收到fail消息之后把对应节点更新为下线状态

集群伸缩=槽和数据在节点之间的移动

*重点->集群扩容
准备新节点-加入集群-迁移槽和数据
1.准备新节点:配置好redis.conf之后，./redis-server ../redis.conf启动redis
2.加入集群：./redis-cli -h ip -p port进入任意一个节点，使用cluster meet ip port 将节点加入到集群中来
集群内新旧节点经过一段时间的ping/pong消息通信之后， 所有节点会发现新节点并将它们的状态保存到本地
对于新加入的节点：新节点刚开始都是主节点状态， 但是由于没有负责的槽， 所以不能接受
         任何读写操作。 对于新节点的后续操作我们一般有两种选择：
         ·为它迁移槽和数据实现扩容。
         ·作为其他主节点的从节点负责故障转移

正式环境建议使用redis-trib.rb add-node命令加入新节点， 该命令内部会
 执行新节点状态检查， 如果新节点已经加入其他集群或者包含数据， 则放弃
 集群加入操作并打印如下信息：
 [ERR] Node 127.0.0.1:6385 is not empty. Either the node already knows other
 nodes (check with CLUSTER NODES) or contains some key in database 0.
 如果我们手动执行cluster meet命令加入已经存在于其他集群的节点， 会
 601造成被加入节点的集群合并到现有集群的情况， 从而造成数据丢失和错乱，
 后果非常严重， 线上谨慎操作

3.收缩集群
下线迁移槽、忘记节点

23.请求路由
Redis接收任何键相关命令时首先计算键对应的槽， 再
根据槽找出所对应的节点， 如果节点是自身， 则处理键命令； 否则回复
MOVED重定向错误， 通知客户端请求正确的节点

cluster keyslot{key}命令返回key所对应的槽
使用redis-cli命令时， 可以加入-c参数支持自动重定向， 简化手动发起重定向操作
节点对于不属于它的键的命令只是做重定向、而不是做转发

*Redis Cluster 命令执行过程:
计算槽， 查找槽所对应的节点，如果不属于自己槽的key，重定向。

cluster keyslot命令就是采用key_hash_slot函数实现的。
例如在集群模式下使用mget等命令优化批量调用时， 键列表必须具有相同的slot
CROSSSLOT Keys in request don't hash to the same slot
这时可以利用haJedisClusterCommandsh_tag让不同的键具有相同的slot达到优化的目的。

如果键内容包含{和}大括号字符， 则计算槽的有效部分是
括号内的内容； 否则采用键的全内容计算槽。

Pipeline同样可以受益于hash_tag， 由于Pipeline只能向一个节点批量发送
执行命令， 而相同slot必然会对应到唯一的节点， 降低了集群使用Pipeline的
门槛。

Redis计算得到相应的槽之后，需要查找槽对应的节点。

针对Redis Cluster 会重定向的问题，效率并不是特别的高，集群客户端通常使用另一种客户端实现
Smart客户端
cluster nodes、cluster info、cluster slots、cluster info

从代码中看到， 获得写锁后再执行cluster slots命令初始化缓存， 由于集
群所有的键命令都会执行getSlotPool方法计算槽对应节点， 它内部要求读
锁。 Reentrant ReadWriteLock是读锁共享且读写锁互斥， 从而导致所有的请
求都会造成阻塞。 对于并发量高的场景将极大地影响集群吞吐。 这个现象称
为cluster slots风暴。

建议升级到Jedis2.8.2以上版本防止cluster slots风暴和写锁阻塞问题， 但
是笔者认为还可以进一步优化。

Jedis为Redis Cluster提供了Smart客户端， 对应的类是JedisCluster

ASK与MOVED虽然都是对客户端的重定向控制， 但是有着本质区别。
ASK重定向说明集群正在进行slot数据迁移， 客户端无法知道什么时候迁移
完成， 因此只能是临时性的重定向， 客户端不会更新slots缓存。 但是
MOVED重定向说明键对应的槽已经明确指定到新的节点， 因此需要更新
slots缓存


第十一章：缓存的设计
·缓存的收益和成本分析。
·缓存更新策略的选择和使用场景。
·缓存粒度控制方法。
·穿透问题优化。
·无底洞问题优化。
·雪崩问题优化。
·热点key重建优化。

使用缓存的成本
1.数据不一致性
2.代码维护成本
3.运维成本

使用缓存的场景
1.开销大的复杂计算
2.加速请求的响应

缓存的删除策略

缓存的更新策略（也就是内存淘汰策略）
redis使用maxmemory-policy配置想指定内存淘汰策略

*低一致性业务建议配置最大内存和淘汰策略的方式使用。
*高一致性业务可以结合使用超时剔除和主动更新， 这样即使主动更新
出了问题， 也能保证数据过期时间后删除脏数据。
*强一致性场景不能使用缓存

缓存的粒度控制
究竟是缓存全部属性还是只缓存部分重要属性呢？ 下面将从通用性、 空间占用、 代码维护三个角度进行说明

缓存全量数据，最通用。但是会占用空间、产生较大的网络开销可能会造成阻塞、全部数据的
序列化和反序列化cpu的开销更大。

缓存击穿的应对（穿透优化）
不要存储冷数据
原因：
第一， 自身业务代码或者数据出现问
题， 第二， 一些恶意攻击、 爬虫等造成大量空命中

应对方法
1.缓存空对象
缓存空对象会有两个问题： 第一， 空值做了缓存， 意味着缓存层中存了
更多的键， 需要更多的内存空间（如果是攻击， 问题更严重） ， 比较有效的
方法是针对这类数据设置一个较短的过期时间， 让其自动剔除。 第二， 缓存
层和存储层的数据会有一段时间窗口的不一致， 可能会对业务有一定影响。
例如过期时间设置为5分钟， 如果此时存储层添加了这个数据， 那此段时间
就会出现缓存层和存储层数据的不一致， 此时可以利用消息系统或者其他方
式清除掉缓存层中的空对象
2.使用布隆过滤器
在访问缓存层和存储层之前， 将存在的key用布隆过滤
器提前保存起来， 做第一层拦截。（在客户端使用pipeline）
这种方法适用于数据命中不高、 数据相对固定、 实时性低（通常是数据
集较大） 的应用场景， 代码维护较为复杂， 但是缓存空间占用少


无底洞问题优化
因为是分布式，键值数据库由于通常采用哈希函数将
key映射到各个节点上， 造成key的分布与业务无关， 但是由于数据量和访问
量的持续增长， 造成需要添加大量节点做水平扩容,导致键值分布到更多的
节点上， 所以无论是Memcache还是Redis的分布式， 批量操作通常需要从不
同节点上获取， 相比于单机批量操作只涉及一次网络操作， 分布式批量操作
会涉及多次网络时间.

一次mget操作需要访问多个Redis节点，
需要多次网络时间。
而图11-7由于所有键值都集中在一个节点上， 所以一次批量操作只需要
一次网络时间

无底洞问题分析：
·客户端一次批量操作会涉及多次网络操作， 也就意味着批量操作会随
着节点的增多， 耗时会不断增大。
·网络连接数变多， 对节点的性能也有一定影响


Redis Cluster使用CRC16算法计算出散列值， 再取对16383的余数就可以算出slot值，

使用hashtag将多个key强制分配到一个节点上。

， 让每种资源都单独运行在自己的线程池
中， 即使个别资源出现了问题， 对其他服务没有影响。 但是线程池如何管
理， 比如如何关闭资源池、 开启资源池、 资源池阀值管理， 这些做起来还是
相当复杂的。 这里推荐一个Java依赖隔离工具
Hystrix。


作为一个并发量较大的应用， 在使用缓存时有三个目标： 第一， 加快用
户访问速度， 提高用户体验。 第二， 降低后端负载， 减少潜在的风险， 保证
系统平稳。 第三， 保证数据“尽可能”及时更新。 下面将按照这三个维度对上
述两种解决方案进行分析



使用redis的建议

1.建议将参数cluster-require-full-coverage配置为no， 当主节点故障时只影
响它负责槽的相关命令执行， 不会影响其他主节点的可用性。
2.cluster-node-timeout:当节点发现与其他节点最后通信时间超过cluster-node-timeout/2时会直接发送ping消息

集群带宽消耗主要分为： 读写命令消耗+Gossip消息消耗。 因此搭建
Redis集群时需要根据业务数据规模和消息通信成本做出合理规划：

3.集群模式下，每条publish数据都会向所有的节点广播，会造成带宽的问题。

4.集群倾斜
集群倾斜指不同节点之间数据量和请求量出现明显差异， 这种情况将加大负载均衡和开发运维的难度
数据倾斜：
·节点和槽分配严重不均。
·不同槽对应键数量差异过大。
·集合对象包含大量元素。
·内存相关配置不一致
请求倾斜：集群内特定节点请求量/流量过大将导致节点之间负载不均， 影响集群均衡和运维成本。

slave-read-only在集群模式下无效（该配置是在主从上的），使用readonly命令打开只读














































































